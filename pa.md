## SIOP Training & Education Guideline
Performance appraisal/management has both a knowledge and a skill base. This area (sometimes also referred to as Talent Management) centers on the methods of measuring and evaluating individuals as they perform organizational tasks, the influence of the social context in which they perform and are evaluated, and on taking action (administrative such as promotion/succession or rewards and/or developmental) with individuals on the basis of such appraisals.

The knowledge base includes a thorough understanding of rating-scale construction and use and rater training. Also relevant are the areas of psychometric theory, measure development, data analysis, criterion theory and development, motivation theory, and the factors that underlie interpersonal perception, judgment, and evaluation (i.e., rating). An understanding of the similarities, differences, and inconsistencies among the perceptions and evaluations of performance and feedback provided by peers, customers, subordinates, and supervisors is essential.

The skill base includes procedures for communicating performance evaluations to job incumbents and coaching them in appropriate means of improving their performance. Also, skill in designing a complete performance appraisal-/management–and-feedback system that meets organizational needs while maintaining and/or enhancing worker motivation and/or performance is required.

## Definitions
- Performance: Goal-relevant actions that are under the control of the individual (Campbell, 1992)
	- It is the behavior, not the evaluation of the results of the behavior (i.e,. effectiveness; Campbell, 1992)
- Behavior: Task statements with no evaluative component
- Effectiveness: Outcomes (e.g., promotion rate, salary level); includes factors beyond the control of the individual (Campbell, 1990)
	- Evaluation of the results of performance

·         _Productivity:_ Ratio of effectiveness to the cost of achieving that level of effectiveness (Campbell, 1990)

o   Lacks intrinsic meaning or relevance; just as arbitrary as any other criterion measure (Mahoney, 1988)

·         _Utility:_ Value of a particular level of performance, effectiveness, or productivity

·         _Performance appraisal:_ Discrete, formal, organizationally sanctioned event, usually not occurring more frequently than once or twice per year

## Deming’s (1986) Argument against Current Practices of PA

·         Performance may be due to org constraints

o   Makes PA unfair

o   Due to faults in the system (e.g., material defect) or faults in a special event or subgroup (e.g., tornado, absence of team member)

·         Promote behaviors that compromise quality

o   When rewards are given for output, achieving outputs becomes the main goal to the detriment of other goals

·         Create a band of discouraged workers who cease trying to excel

o   Fault lies in relative rankings and forced distributions that grade on a curve

·         Rob workers of pride in workmanship

o   Often done in relative terms which encourages average output rather than quality development.

o   Workers chose to do what everyone else does to “get by”

## Chorpade & Chen (1995) Five Realities of PA

·         PA is inevitable

·         PA is fraught with consequences for the individual and the organization

·         As job complexity increases, it becomes progressively more difficult to assign accurate merit based performance ratings

·         There is an ever-present danger of parties being influence by political consequences of their actions

·         The implementation of performance management systems takes time and effort , and all participants must be convinced the system is useful and fair

## Why Appraise

·         Cascio, 2005

o   _Strategy_: Link employee activities with the organization’s mission and goals

o   _Communication_: Provide concrete feedback to employees

o   _Employment decisions_: Serve as predictors for promotion

o   _Research_: Serve as criteria for HR research (test validation)

o   _Developmental_: Establish objectives for training decisions

o   _Facilitate organization diagnosis and development_

·         Campbell & Wiernik, 2015 review

o   Research purposes

§  Reliability, construct validity important

o   Legal purposes

§  Reliability, construct validity important

o   High stakes decisions (e.g., compensation, selection)

§  Fairness, transparency, use of JA, accuracy, motivation

§  Criterion-related validity, reliability important

o   Self-managed performance

o   Performance feedback

§  Should be specific and task-related (Kluger & DeNisi, 1996)

## Historical Perspective on Appraisal Research (Farr & Levy, 2007)

·         Started with assessment in the military

·         In earlier years, focused on rating accuracy

o   Rater biases dominated research (e.g., halo, leniency)

o   Classic methods of scale development have not been replaced by newer methods designed to eliminate psychometric artifacts because newer methods (e.g., forced choice) make raters feel like they lose control of the process

o   Lots of research on the scales themselves and development of first scales

·         By late 1950s, use of PA expanded from judgment  and decision making to feedback and development

·         In 1960s, increasing emphasis on feedback and the role of the supervisor-employee appraisal interview

·         1960-1970s: Developed more scales that focused on behavior (e.g.,BOS, BARS)

o   Still a huge focus on rating format

·         In 1980s, paradigm shift toward the use of cognitive frameworks

o   Landy and Farr (1980) call for a moratorium on appraisal format research

·         In 1990s, social-psychological paradigm (Murphy & Cleveland, 1991)

o   Recognition that appraisal takes place in a social context and ‘hot cognition’ plays a big part (Cleveland & Murphy, 1992)

o   In 1/3 studies, feedback _decreased_ performance, regardless of the sign of feedback received (Kluger & DeNisi, 1996)

·         In 2000s, consider the ratee and movement toward performance _management_ as opposed to appraisal

o   Reactions to appraisal affect willingness to act on feedback (Levy & Williams, 2004)

o   PA is a matter of judging, not simply measuring people (Farr & Levy, 2007)

o   Motivational framework (DeNisi & Pritchard, 2006)

§  Individuals have a certain amount of energy at any time

§  Have a certain number of needs at any time

§  More likely to exert time and effort to meet needs

§  Focus on results which person has control over

§  Motivational process to improve performance is as follows: Action -> Results -> Evaluation -> Outcomes -> Needs satisfaction

·         PA can intervene and make these links stronger (i.e., motivate performance)

## Steps of Performance Appraisal

·         Step 1: JA

o   Identifies components of a job

o   Task inventory is probably more appropriate for defining the important elements of performance on a job (Hollenbeck & Borman, 1976)

o   Critical incidents technique might be especially valuable for establishing the KSAs that account for success or failure (Hollenbeck & Borman, 1976)

·         Step 2: Performance standards

o   Provide critical link to the process

o   Develop this instrument carefully – whole section on this below

·         Step 3: Performance appraisal

o   Includes both observation and judgment

o   Train supervisors how to use the system

o   Should have an appeals process

o   Performance evals should be clearly documented in detail

o   Provide corrective guidance for poor performance

# Criterion Development

## The Criterion Problem

·         The criterion problem refers to the dilemma of job performance measurement (Austin & Crespin, 2006)

·         Three reasons the criterion problem may exist (Austin & Villanova, 1992)

o   Choice of dimensions to represent a criterion construct depends on how broadly one initially construes the conceptual criterion

o   Dimensions of criteria are context dependent

o   Failure to articulate the values involved in decisions to include some measures of performance criteria while excluding others

·         How we choose to operationalize our latent construct will determine how we measure it and how raters will see it

·         Need to focus on developing sound performance criteria and linking criteria with other constructs of interest

o   Criteria should be measured without halo and other sources of error

o   Less than 10% of variance in job performance ratings could be attributed to performance-related information. Everything else was error (Viswesvaran et al., 2005)

## Defining Criteria

### Overview (Cascio, 2005; Austin & Villanova, 1992)

·         Represents something important or desirable. Evaluative standard that can be used to measure a person’s performance, attitude, motivation, etc.

·         Something which may be used as a ‘measuring stick’ for gauging the tests designed to predict that proficiency; must be able to discriminate differing levels of performance

·         Index of occupational proficiency that is used to evaluate tests designed to predict that proficiency

### Ultimate Criteria (Thorndike, 1947)

·         A hypothetical criterion construct that describes the full domain of performance

o   Includes everything that defines success on the job

o   Can be thought of as a special case of composite criteria

### Conceptual Criteria (Austin, 1964)

·         A verbal statement of importance or socially relevant outcomes

·         A framework to base judgments

·         Best described when performance requirements can be clearly and unambiguously described in words

#### Criterion/Actual Measures

·         Operational definitions of the conceptual criteria

·         Designed to measure conceptual criteria

#### Criterion Performance

·         Observable event that is judged to be relevant to the conceptual criterion

## Criterion Development Steps

·         _Criterion development:_ Procedures undertaken to develop measures of job performance that are sound in psychometric terms

### Guion (1961) Five Step Procedure

·         Analysis of the job and/or organizational needs

·         Development of measures of actual behavior relative to expected behavior as identified in the job and needs analysis

·         Identification of criterion measures underlying such measures by factor analysis

·         Development of reliable measures, with construct validity

·         Determine predictive validity of each predictor for each one of the criterion measures

### Borman (1991)

·         The most rational way to conduct criterion development begins with a job analysis

·         Conceptual criteria should be carefully identified to include all dimensions of performance

·         Use critical incidents or BARS methodology

·         Attempts can be made to identify or develop operational measures related to each component of the conceptual criterion

## Challenges in Criterion Development

·         Reliability

o   Solution: Aggregate the behavior over situations or occasions to cancel out effects of incidental and uncontrollable factors

o   _Intrinsic Unreliability:_ Personal inconsistencies of performance of an individual

o   _Extrinsic Unreliability:_ Due to sources of variability that are external to job demands or individual behavior (e.g., weather conditions)

·         Validity

o   Messick’s (1995) idea of validity as a multifaceted inquiry is challenging to meet in practice (Austin & Crespin, 2006)

o   Nonetheless, criterion can be validated through various strategies (e.g., using work samples)

o   Also can bust the validity ceiling by expanding the criterion domain (Campbell, 1990)

·         Job performance observation

o   Different methods may lead to different conclusions (Bray & Campbell, 1986)

·         Dimensionality of performance

o   See section on models of job performance. We probably need more than one dimensions

## Evaluating Criteria (Cascio, 2005)

·         Sensitivity: Capable of discriminating between effective and ineffective employees

·         Acceptable

·         Reliable

·         Relevant: Logically related to the performance domain in question

o   The most appropriate criterion for evaluating tests is a direct measure of the degree of job proficiency developed by an employee after an appropriate period of time on the job

·         Practicality

·         Important

·         Observable

## Factors to Consider When Developing Criteria

### Level of Specificity (Spector, 2003)

·         Methods used to assess performance should be based on the purposes of the assessment information

·         For developing an employee’s skills, it is better to focus on the individual task so feedback can be specific

·         For admin purposes, overall job performance might be more important than specific tasks

### Criterion Complexity

·         Often need multiple measures to capture performance

·         Can create composites or keep each measure separate

#### Composite Criteria (Cascio, 2005)

·         Provide an overall measure of success or value to the organization

·         When forming a composite, carefully consider the relative importance of each criterion measure

·         Useful in decision making and comparisons across individual

·         If criterion measures are highly correlated within a job, the combining them to form a composite may be appropriate

·         May be preferred when comparing employees on overall performance

#### Multiple Criteria

·         Advocates contend that measures of different criteria should not be combined

·         Skills can be related to success but not related to each other; a composite of unrelated skills may not make sense

·         If individual criterion elements refer to different kinds of performance, different predictors may correlate differently with different performance areas. A composite may mask this.

·         Preferred when giving employees feedback

### Contamination, Deficiency, and Relevance

#### Criterion Contamination

·         Part of the actual criterion that reflects something other than what it was designed to measure.

·         Can arise from biases in the criterion and unreliability

·         When a criterion taps into irrelevant variance to the performance requirements

·         When the actual or operational criterion include variance that is unrelated to the ultimate criterion

o   _Error:_ Random variation that cannot correlate with anything except by chance alone

o   _Bias:_ Systematic criterion contamination. It can correlate with predictor measures

§  May serve to increase or decrease the obtained validity coefficient or not influence validity

§  Bias due to knowledge of predictor information can occur when the rater is aware of an employee’s score on selection methods

§  Bias due to group membership

§  Bias in ratings may be due to inadequate observation by the rater, unequal opportunity for subordinates to demonstrate proficiency, rater prejudices, or inability to adequately rate individuals (e.g., halo)

#### Criterion Deficiency

·         The actual criterion does nto adequately cover the entire theoretical criterion

o   i.e., lack of content validity

#### Criterion Relevance

·         Extent to which the actual criterion assesses the theoretical criterion

o   i.e., construct validity

·         The correspondence between criteria and the actual performance demands of the job

#### Criterion Equivalence

·         If two criteria are equivalent, then they are measuring precisely the same characteristics

### Dynamic Criteria

·         Variability of performance over time.

·         It is the performance and not the standard that changes

·         There is a lack of research on the degree of variability in people’s performance over time

·         See major section, Dynamic Criteria

### Static, Temporal, and Individual Dimensionality

#### Static Dimensionality

·         Individuals may be high on one performance facet and simultaneously low on another (e.g., task and contextual performance)

·         Distinction between maximal and typical performance is relevant here (Cronbach, 1960)

o   _Typical performance:_ Average level of performance (will do)

o   _Maximal performance:_ Peak level of performance (can do)

o   Typical and maximal performance correlated .42 (corrected; Beus & Whitman, 2012)

·         Job performance is a combination of maximum (declarative and procedural knowledge) and typical (motivation) performance (Campbell, 1990)

o   Not highly correlated for new hires (r = .14; Sackett et al., 1988)

·         Typical performance may be more important to consider when predicting long term occupational performance (Ackerman, 1994)

#### Temporal Dimensionality

·         _Immediate criteria:_ Near-term measures

·         _Intermediate criteria:_ Measured at a later time, usually about 6 months

·         _Summary criteria:_ Expressed in terms of long-term averages of totals

#### Individual Dimensionality

·         Employees can be equal in the quality of their performance but the nature of their contribution might differ.

·         Jobs can have the same title and be qualitatively different in a psychological sense (Borman, 1991)

### Six Possible Extra-Individual Influences on Performance

·         Environmental and organizational characteristics: Pay, promotion, group cohesiveness, satisfaction, role clarity, autonomy, age tenure, mood

·         Environmental safety: Injuries and loss of time can moderate performance

·         Life space variables: Important conditions that surround the employee on and off the job

·         Job and Location: Structural and contextual factors; policies and practices of the organization

·         Extra-Individual Differences and Sales Performance: Territory workload, market share, advertising

·         Leadership

# Models of Job Performance

## Historic Approaches

### Bernardin and Beatty (1984)

·         Every job can be assessed in terms of: quality, quantity, timeliness, cost-effectiveness, need for supervision, and interpersonal impact

### Binning and Barrett (1989) Model

·         Explain inferences that we use to link performance and predictors in theory and data land

·         _Criterion related validity:_ Use empirical evidence (criterion measures) to show predictor measures relate to performance by showing a relationship between the predictor and the criterion measures

·         _Construct validity:_ Showing that a predictor measures an underlying construct that affects performance allows one to use the predictor to measure performance

·         _Deriving job specifications:_ Constructs underlying performance have been identified

·         _Job descriptions:_ Actual job demands have been adequately assessed

·         _Criterion problems:_ Difficulties involved in the process of conceptualizing and measuring performance constructs that are multidimensional, dynamic, and appropriate for different purposes

### Murphy (1990)

·         Four dimensions of performance: downtime behaviors, task performance, interpersonal behaviors, destructive behaviors

## Campbell et al. (1996)

·         Review of performance models

### Defining Performance

·         Includes only those actions or behaviors that are:

o   Relevant to the organization’s goals

o   Can be measured in terms of each individual’s proficiency

·         Human resources management practices must reward, punish, teach, and influence those things that the individual can control if practices are to be fair and equitable

### Classic IO Approach to Modeling Performance

·         A general factor exists that accounts for almost all relevant true score covarainces among observed measures

·         Goal of measurement is to obtain the best possible measure of the general factor with the best possible measure being an objective indicator of the individual’s overall contribution

### Multiple Factor Model (Campbell, 1990)

·         Performance is genuinely multidimensional and is composed of a number of distinguishable components

·         First major theory of job performance; stimulated research on the topic

#### Eight Factor Taxonomy (Campbell, 1990)

o   _Job-specific task proficiency:_ Perform the core substantive or technical tasks that are central to the job

o   _Non-job-specific task proficiency:_ Perform behaviors that are not specific to the particular job

o   _Written and oral communication_

o   _Demonstrating effort:_ The frequency with which people expend extra effort when asked, and the frequency with which they keep working under adverse conditions

o   _Maintaining personal discipline:_ The degree to which negative behaviors at work are avoided

o   _Facilitating peer and team performance:_ _Individual supports his/her peers_

o   _Supervision/Leadership_

o   _Management administration_

·         Three of the dimensions are common components for all jobs: core task proficiency, demonstrating effort, personal discipline (Campbell, 1990)

#### Performance Determinants

·         Most behaviors are the result of a complex interaction between characteristics of people and characteristics of the environment

·         Differences in job performance are caused by the interaction among ability, motivation, and situational factors that may facilitate or inhibit performance

·         Direct

o   _Declarative knowledge:_ Knowing what to do

§  Sets employee up to acquire procedural knowledge/skill

o   _Procedural knowledge:_ Knowing how to do it

§  Performance potential

§  Whether potential leads to job performance depends on motivation

o   _Motivation:_ Effect choices directed towards a goal

§  Choice to perform

§  Level of effort

§  Persistence with effort

·         Indirect

o   Can only lead influence performance through direct determinants

o   Personality

o   Ability

o   Interests

### National Research Council Model

·         Performance is the proficiency with which the individual can do the technical tasks or has mastered the substantive content of the job

·         E.g., standardized job sample

### Critical Task Model

·         Identify a smaller number of only the most critical tasks

### Critical Deficiency Model

·         Critical task failures that differentiate jobs (e.g., airline pilots)

### Attrition/Turnover Model

·         Turnover is accounted for by the economic cycle and individual temperaments in the military.

·         In the private sector turnover due to compensation, benefit practices, training opportunities, and management practices

## Performance as Behaviors (Campbell et al., 1993)

·         Performance = behaviors, NOT outcomes (effectiveness)

·         Make several other bold claims

o   A general factor cannot possibly represent the best fit for performance

o   The notion of an ultimate predictor is meaningless

o   The subjective vs. objective criterion distinction is a false issue

## Task and Contextual Performance (Borman & Motowidlo, 1993)

·         _Task performance:_ Behaviors that contribute to an organization’s technical core

·         _Contextual performance:_ Behaviors that contribute to organizational effectiveness through its effects on the psychological and social aspects of the organization

·         Task performance and contextual performance equally related to overall performance (.43 vs. .41) (Motowidlo & Scotter, 1994)

·         Cognitive ability = best predictor of task performance

·         Personality = best predictor of contextual performance

·         Performance determinants are knowledge, skills, and habits (Motowidlo, 1997)

## Four Dimension Taxonomy (Murphy, 1994)

·         _Task oriented behaviors_: Performing the major tasks associated with one’s job

o   Mirrors job specific task proficiency dimension in Campbell 1990 model

·         _Interpersonally oriented behaviors:_ Represents all of the interpersonal transactions that occur on the job

·         _Down time behaviors:_ Represents behaviors that may lead the job incumbent to be absent from the worksite including counterproductive behaviors

·         _Destructive/hazardous behaviors:_ Include such things as safety violations, accidents, and sabotage

·         Based on job performance in the U.S. Navy

o   Broad dimensions

o   Designed to explain a narrow set of jobs

o   Less useful than Campbell’s nine components

## Task Performance, OCB, CWB (Viswesvaran & Ones, 2000)

·         Expand on task and contextual performance (Borman & Motowidlo, 1997) to identify three dimensions

·         _Task performance:_ Proficiency with which incumbents perform activities that are formally recognized as part of their jobs

o   Contribute to the org technical core by providing materials or services

·         _Organizational citizenship behavior:_ Individual behavior that is not explicitly recognized by the organization’s formal reward system

o   Promotes the effective functioning of the organization

·         _Counterproductive behaviors:_ Behaviors that have negative value for organizational effectiveness

## Adaptive Performance (Pulakos et al., 2000)

·         Developed eight dimension taxonomy of adaptability in the workplace

o   Handling emergencies or crisis situations

o   Handling work stress

o   Solving problems creatively

o   Dealing with uncertain and unpredictable situations

o   Learning work tasks, technologies, and procedures

o   Demonstrating cultural adaptability

o   Demonstrating physically oriented adaptability

·         Can be reactive or proactive

·         In response to actual or anticipated future changes in the environment

·         Perception of change can be a result of better understanding of the environment

·         Predictors of dimensions

o   Trainability (important!!)

o   Emotional stability

o   Flexibility

o   GMA

·         Using adaptive performance as a criterion

o   Learning dimension is relevant to all jobs

o   Good for jobs that change, are high complex and inconsistent, and for orgs that require employees to continuously learn

·         Can measure using BARS, peer and self-ratings, work samples, cast studies, role plays, SJTs

o   Be sure to focus on change in approach to challenges; not just dealing with increased difficulty

## Performance as the Total Expected Value of Performance Episodes (Motowidlo, 2003)

·         Job performance is the _total expected value_ to the organization of _the discrete behavioral episodes_ that an individual carries out over a standard period of time

·         Units of performance are performance episodes

o   Can be positive or negative

·         Expected organizational value = instrumentality of behavior x valence of the outcome

·         Identified through critical incident technique

·         Does not contradict previous performance models

o   Campbell’s model divides behaviors based on content

o   Borman & Motowidlo 1993 divide behaviors based on organizational consequences

o   Viswesvaran et al., 2005 identify performance factors according to commonalities in their antecedents

·         Causal mechanisms

o   Ability -> capacity to learn

o   Experience -> opportunity to learn

o   C -> motivation to learn

o   Dispositional fit -> How some interpersonal characteristics affect relevant job performance

## General Factor of Performance (Viswesvaran et al., 2005)

·         General factor accounted for a great deal of variance among observed measures (also seen in Viswesvaran, 2003)

·         Average true score between-rater correlation between dimensions

o   .54 Controlling for halo

·         Halo does inflate supervisor and peer ratings. Halo accounts for:

o   33% of variance for supervisor ratings

o   63% of variance for peer ratings

·         When controlling for halo, the general factor accounts for 60.3% of the variance among corrected correlations

o   GMA and C is a key part of all job dimensions

o   General factor represents the proportion of total variance in performance attributable to GMA and C

·         There can still be sub dimensions of performance; does not preclude multidimensional models

## The Universally Invariant Model of Job Performance (Campbell, 2012)

·         Basically Campbell revised his model to better center on communalities between all of the research done to-date on performance

·         Three proximal determinants are still the same; mediational proposed relationships are still the same

·         Eight dimensions of performance changed and subdimensions were identified.

·         I don’t care enough to write it all down. You can look it up or check out - Campbell & Wiernik (2015) Annual Review

# Organizational Citizenship Behaviors (OCBs)

## Overview

·         Organ (1988): Individual behavior that is discretionary, not directly or explicitly recognized by the formal reward system

·         Organ (1997) updated definition of OCB: Performance that supports the social and psychological environment in which task performance takes place

o   Not appropriate to refer to OCB as extra-role; employees and employers often view OCBs as part of the job responsibilities

o   Congruent with contextual performance              

·         In the aggregate believed to enhance effectiveness of groups and organizations

o   OCB is empirically related to effectiveness

o   Direction of causality is unclear (some evidence that it is causal in Podsakoff et al., 2009 meta)

·         Not clear whether employees engage in OCBs without the expectation that those behaviors will be rewarded

o   _Impression management:_ When OCB is performed with the expectation of future rewards it becomes a form of impression management rather than altruistic behavior (Bolino, 1999)

o   _Contextual performance:_ OCB behaviors should be used in formal performance evaluations (Borman & Motowidlo, 1993)

## Structure of OCBs

### Two Dimensions (Smith et al., 1983; Organ & Konovsky, 1989)

·         Compliance: Following the rules and doing whatever is needed to get the job done

·         Altruism: Helping others at work when they have a problem

### Five Dimensions (Organ, 1988)

·         Expanded on Smith two dimensions

·         Used as the basis for most OCB studies; lots of empirical support

·         _Altruism:_ Helping behaviors, pro-social behavior (e.g., help coworker)

·         _Courtesy:_ Basic consideration for others (e.g., touch base with coworker)

·         _Sportsmanship:_ Not engaging in certain forms of behaviors (e.g., complaining)

·         _Conscientiousness:_ Being a good citizen (e.g., arrive on time for meetings)

·         _Civic virtue:_ Target is the organization or worker group rather than the individual (e.g., charitable function)

### Three Factor Model (Coleman & Borman, 2000; Williams & Anderson, 1991)

·         Used EFA, MDS, and cluster analysis

·         Typically (not always) found a three factor solution

o   Interpersonal citizenship performance (personal support; Borman et al., 2001)

o   Organizational citizenship performance (organizational support; Borman et al., 2001)

·         Job/task citizenship performance (conscientious initiative; Borman et al., 2001)

### Seven Common Dimensions of OCB (Podsakoff et al., 2000)

·         _Helping behavior:_ Voluntarily helping others with, or preventing the occurrence of, work related problems

·         _Sportsmanship:_ A willingness to tolerate the inevitable inconveniences and impositions of work without complaining

·         _Organizational loyalty:_ Promoting the organization to outsiders, protecting it, defending it against external threats, and remaining committed even under adverse conditions

·         _Organizational compliance:_ Person’s internalization and acceptance of the organization’s rules, regulations, and procedures, which results in a scrupulous adherence to them. Even when no one observes or monitors compliance.

·         _Individual initiative:_ Engaging in task-related behaviors at a level that is so far beyond minimally required or generally expected levels

·         _Civic virtue:_ Macro-level interest or commitment to the organization as a whole

·         _Self-development:_ Voluntary behaviors that employees engage in to improve their KSAs

·         Not much empirical support for this model

### One Factor of OCB (Lepine, Erez, & Johnson, 2002)

·         Lots of dimensions of OCB; are they all really distinct?

o   So many models – a few not reviewed here because not really used or validated

o   Lots of construct overlap with varying degrees of specificity

·         Meta showed strong relationships among all of the OCB dimensions

·         Should think of OCB as a single latent, or aggregate, construct

·         OCB-I and OCB-O do not explain unique variance beyond one another

·         Limitation: Could be common method variance

·         Hoffman et al., 2007 also finds the evidence points to a single factor model

## Measurement

·         Multisource, typically supervisor and peer ratings

·         Self-ratings have limited value

·         Agreement scales

## Predictors

·         Situational

o   Cognitive evaluations of the fairness of employee treatment by an organization (Organ & Ryan, 1995 meta)

§  Rooted in equity theory (Adams, 1965)

§  Employees evaluate work situations by comparing inputs to outcomes received

o   Job-related stressors (Jex, 1998)

o   Job satisfaction (Organ & Ryan, 1995 meta)

o   Trust in the leader (Wang et al., 2005)

o   LMX and transformational leadership

·         Dispositional

o   CANO (individually, _r_ < .20) (Borman et al., 2001; Ciaburu et al. 2011 meta)

o   Proactive personality

o   Narcissism

o   GMA (weak)

o   Positive/negative affect (Borman et al., 2001)

o   Helpfulness (Borman et al., 2001)

o   Dependability (Borman et al., 2001)

## Outcomes (Podsakoff et al., 2009 meta)

·         Turnover intentions, absenteeism, performance ratings

·         Org productivity and efficiency, reduced costs, customer satisfaction, unit-level turnover

## Why OCBs Influence Performance Ratings

·         Norms of reciprocity

o   Employee helps you out, you return the favor by giving a good evaluation

·         Implicit performance theory

o   Supervisor sees employee performing OCB, fits implicit idea of good performer

·         Schema-triggered affect

o   Supervisor has OCB and high performance in definition of good employee

o   Employee who exhibits OCB will trigger positive affect, leading to better performance ratings

·         Behavioral distinctiveness and accessibility

o   Supervisor asked to be distinctive in ratings; OCB may stand out

·         Attributional process of accessibility

o   Attributes of performance that are stable, internal causes are most likely to stand out when making evaluations

o   OCB is not required, but it may be viewed as a stable trait

·         Illusory correlations

o   Tendency for people to see two events as occurring together more often than they actually do

## Why OCBs Influence Organizational Effectiveness

·         Enhance coworker productivity

·         Enhance managerial productivity

·         Free up resources for more productive purposes

·         Reduce need to devote scarce resources to purely maintenance functions

·         Serve as effective means of coordinating activities between team members and across work groups

·         Enhance organization’s ability to attract and retain the best people by making it a more attractive place to work

·         Enhance stability of organizational performance

·         Enhance organization’s ability to adapt to changes

## Role of OCB in Performance Ratings

·         Effect of interpersonal factors in ratings (Borman et al., 1995)

o   Ratee ability, knowledge, and proficiency accounts for 13% of variance in supervisor ratings and 7% in peer ratings

o   Interpersonal factors increased variance accounted for to 28% and 19% respectively

o   Supervisors weigh contextual performance at least as highly as task performance (also replicates Motowidlo & Van Scotter (1994)

·         Laboratory study on effects of OCB (Whiting et al., 2008)

o   Above and beyond task performance, helping behavior, voice, and org loyalty contribute to performance appraisal decisions

o   Raters take different types of OCB into account when rating (not just helping behavior)

o   OCB is required for good ratings

# Counterproductive Work Behaviors (CWBs)

## Overview

·         Among the most important criteria (Hoffman & Dilchert, 2012) because it costs companies billions

·         _CWB:_ Intentional behavior that is viewed by the organization as contrary to its legitimate interest (Sackett & DeVore, 2001)

o   Makes it difficult for organization to achieve its goals

o   Makes no assumption regarding motives or causes underlying CWB

o   Other definitions expand to include acts that harm employees, customers, or other stakeholders (not just the org) (Spector & Fox)

·         Different from the negative end of OCBs; should not measure the two on a single continuum (Spector et al., 2010; Ones & Dilchert, 2013; Berry et al., 2007)

·         Common forms: ineffective job performance, absenteeism, turnover, unsafe behavior

·         Less common forms: Theft, violence, substance use, sexual harassment)

·         Can be interpersonally or organizationally directed (Robinson & Bennett, 1995; Ones & Dilchert, 2013)

o   Different facet scales of CWB intercorrelate substantially

·         Spector (2003) differentiates between withdrawal behaviors and CWB

o   CWB intends to harm, whereas withdrawal are not always intentional or harmful

## Structure of CWBs

### Typology of Workplace Deviance (Robinson & Bennett, 1995)

·         Empirically-driven dimensions

o   Minor to serious

o   Interpersonal to organizational

·         Creates four quadrants of deviant behavior

o   _Property deviance:_ Organizational and seriously harmful

§  Sabotaging equipment, lying about hours, stealing from company

o   _Production deviance:_ Organizational and minor

§  Leaving early, wasting resources

o   _Personal aggression:_ Interpersonal and seriously harmful

§  Sexual harassment, verbal abuse, stealing from coworkers

o   _Political deviance:_ Interpersonal and minor

§  Showing favoritism, gossiping, blaming coworkers

### Eleven Categories (Gruys, 1999; Gruys & Sackett, 2003)

·         Theft and related behavior

·         Destruction of property

·         Misuse of information

·         Misuse of time and resources

·         Unsafe behavior

·         Poor attendance

·         Poor quality work

·         Alcohol use

·         Drug use

·         Inappropriate verbal actions

·         Inappropriate physical actions

·         Categories vary on two dimensions:

o   Task-reelvance

o   Interpersonal-organizational

·         Appears to be differential relationships between antecedents of CWB and interpersonal and organizational dimensions of CWB (Berry et al., 2007)

o   Interpersonal and organizational are correlated .62

### One Factor (Ones & Dilchert, 2013)

·         Found strong evidence for a general factor of CWB

## Common CWBs

### Ineffective Job Performance

·         Detecting ineffective performance

o   Performance related data typically provide information about the impact of employee behavior, rather than the behaviors themselves

o   Three types of performance-related behavior

§  _Personnel data:_ Absences, sick days, tardiness, safety violations, disciplinary actions. May provide a direct measure of some CWBs

§  _Production data:_ Information about tangible outcomes associated with job performance (e.g., sales commission)

·         Limitation: Often provides overly simplistic view of performance

§  _Subjective evaluations:_ Subjective evaluations from immediate supervisors

·         Most common

·         Typically measures result of employee behavior (i.e., effectiveness)

·         Benefit: Provides considerable insight into effective performance

·         Limitation: Often only marginal value in detecting ineffective performance, poorly administered or ignored

o   Electronic performance monitoring

§  Common for customer service call centers

·         Causes of ineffective performance

o   _Attribution theory:_ People use several pieces of info when determining the cause of a behavior. Consistency of behavior over time, between different settings, and in comparison with others

§  _Internal attribution_: Ineffective performance consistent over time and settings; seen as poor in relation to others

§  _External attribution:_ Ineffective performance not consistent over time and settings and not seen as poor in relation to others

§  _Fundamental attribution error:_ Bias towards attributing the cause of other behavior to internal rather than external causes

o   Issues with the individual include lack of ability, skills, or motivation

o   Issues with environment

§  Selection error that involves hiring individuals who lack skills or who do not fit with the org culture

§  Inadequate training

·         Inadequately trained on tasks

·         Failure to provide info about culture

·         Mixed signals abou the cultures

§  Deficiencies in the environment

§  Organizational constraints (e.g., poorly structured tasks)

·         Managing ineffective performance

o   First talk to the employee

o   Change employee behavior

§  Training interventions

§  Counseling or employee assistance programs (Cooper et al., 2003)

·         To help with nonwork issues that may be affecting performance

o   Changing factors in the workplace

§  Reengineering (look for issues and bottlenecks in tasks and processes)

§  Task analysis to see environmental constraints

·         Preventing ineffective performance

o   Effective selection programs

o   Proper training and socialization

o   Have systematic performance measurement and feedback systems

o   Respond appropriately to performance differences

o   Organizational response to consistent pattern of ineffective employee performance

§  If it is an ability problem transfer to a new position; be sure this is not seen as a reward

§  _Progressive discipline:_ Reprimand that increases in severity, ultimately leading to termination

### Workplace Violence

·         How to prevent violence

·         Personnel selection

o   Use background checks

o   Check for physical assault

·         Security

o   Installation of security cameras

o   Security guards

o   Employee access badges

·         Violence policies

o   Organizations must articulate a lack of toleration for violence

·         Organizational climate

o   Fair treatment

o   Comfortable environmental factors

o   Treating employees with trust

·         Employee support

o   Employee assistance and training supervisor to use it

### Employee Absenteeism

·         Not attending work

o   _Excused absences:_ Those that are due to reasons the organization deems as acceptable

o   _Unexcused absences:_ Those that are due to either unacceptable reasons or cases where employees have not followed proper procedures

o   Different types have different antecedents

·         Key variables:

o   Organizational culture

o   Organizational policies

·         Measurement

o   _Time loss measures:_ Number of days or hours missed for a given period of time

§  Preferred because tends to have larger variability than the other measures

o   _Frequency measures:_ Number of days absences occurred for a given time (3 consecutive days = 1 absence)

o   Low base rate; need to look over a longer period of time

·         Predictors

o   Ability vs. desire

§  Ability to attend impacted by health, nonwork responsibilities, weather, reliability of transportation

§  Desire to attend impacted by employee feelings about the org or the job

o   Affective predictors

§  Job satisfaction (r = .10)

§  Organizational commitment

o   Other variables

§  Gender – women more frequently absent than men (work/nonwork balance issues?)

§  Absence control policies (stricter = less absences)

§  _Absence culture:_ Group level beliefs and norms about absenteeism

§  Positive affect (but not negative affect) (Iverson & Deery, 2001)

·         Cross-cultural issues

o   Not much research

o   Chinese may be more tolerant of domestic reasons for absence and more impacted by group norms compared to Canada

·         Preventing absenteeism

o   Make attendance more rewarding to the employee

§  Job redesign

§  Greater opportunities to participate in decision making (job enrichment)

§  Higher levels of support

§  Compensation for some percentage of unused sick days

o   Make absenteeism less attractive

§  Negative consequences for frequent unauthorized absenteeism (loss of pay, termination)

o   Help reduce constraints on employees

§  Child care or elder care services/referrals?

§  Public transportation

### Employee Turnover

·         Key Variables

o   Job satisfaction/organizational commitment

o   System constraints

o   Alternative options

·         Optimal vs. dysfunctional turnover

o   Optimal turnover

§  Poorly performing employee decides to leave an organization

§  Sometimes not in the best interest to retain high performing employee because of costs of retaining the individual

o   Dysfunctional turnover

§  If turnover rate is extremely high

§  High costs of recruiting and training

§  High percentage of good employees leave

§  May tarnish organization image

·         Avoidable vs. unavoidable turnover

o   Avoidable turnover

§  Can potentially create a safer work environment to reduce injuries

§  Encourage healthy behaviors to reduce illness

§  Provide flexible work arrangement, on-site childcare

§  Examine exit factors using exit interview and focus groups

o   Unavoidable turnover

§  Can’t do anything about this.

·         Note that downsizing is not synonymous with turnover (McElroy et al., 2001)

·         Predictors

o   Affective

§  Mattieu & Zahac (1990)

·         Org commitment (-.25)

§  Carsten & Spector  (1987)

·         Satisfaction (-.24)

·         Behavioral intention to turnover (.32)

§  Satisfaction and g have stronger relationships in the beginning, but this decreases over time (simplex pattern)

o   Non-Affective

§  Performance (weak; Williams & Livingston, 1994 meta; also Griffeth et al., 2000 meta)

·         May be a curvilinear relationship (Jackofskey, 1984)

·         May be strongest when high reward contingencies

·         Low base rate

·         Range restriction due to homogenous level of performance among employees who stay

§  Griffeth et al., 2000 meta

·         Tenure (-.21)

·         Satisfaction with supervisor (-.10)

·         Workplace stress and stressors (relatively weak)

·         Alternative job opprotunities (.11)

·         Comparison of alternatives with present job (.14)

§  Barrick & Zimmerman (2005)

·         Self confidence and decisiveness

·         Desire for position

·         Intent to quit pre-hire

§  Relationship with pay is not that large (Kammeyer-Mueller et al., 2001)

·         Theoretical perspectives

o   Mobley’s (1977) Model of Turnover

§  Dominated for the past 25 years

§  Employee affect plays a key role in turnover process (satisfaction, commitment)

§  Turnover is usually due to willingness to get away from the present job rather than unattraction to alternatives

o   Unfolding model of the turnover process (lee & Mitchell, 1994)

§  Basic assumption is that individuals do not evaluate their jobs unless forced to do so

§  _Shock to the system:_ An event that forces an employee to review his or her job situation

·         Programmed response if the system has come up before

·         If no programmed response, use controlled cognitive processing to consciously evaluate whether the shock to the system can be resolved by staying in the organization (evaluate commitment to eh org)

§  No shock but turnover is affect initiated, or dissatisfied over time

o   Job embeddedness (Lee et al., 2004)

§  Combination of forces in one’s personal and professional lives that keeps a person from changing employment

·         E.g., social role in the org, family situation, commutniy involvement

§  Good predictor of voluntary turnover

### Accidents

·         Determinants of accidents

o   Personal characteristics

§  Tenure negatively associated with accident frequency

§  _General social maladjustment:_ Variety of negative characteristics, such as lawbreaking, immaturity, substance abuse problems, etc.

§  _Distractibility:_ Captures the extent to which people have trouble concentrating and whether their attention can easily be diverted

§  More accidents for younger, distractible, those higher on social maladjustment

o   Safety climate (Griffin & Neal, 2000)

§  Prevailing norms and values surrounding safety issues in an organization

·         Employees work in a social environment, and this impacts safety (Neal & Griffin, 2006)

§  Safety climate associates with lower accident involvement, compliance with safety features, and participation in more proactive safety behaviors (Clarke, 2006 meta)

·         Accident prevention

o   _Physical factors:_ Make equipment and other features of the environment safer

o   _Behavior modification:_ Encourage employees to use safe work practices and discourage employees from being unsafe

o   _Selection:_ Means of screening out employees who are likely to be unsafe

o   Changing or improving safety climate

## Less Common CWBs

### Employee Theft

·         Employees taking things from the organization that don’t belong to them

·         Causes

o   Characteristics of the individual (integrity)

o   Retaliation against unfair or frustrating organizational conditions

§  Moderator: Locus of control; tend to see stronger relationship with external LOC (Spector, 1997)

### Workplace Violence

·         Physical acts of aggression by members of an organization carried out in an organizational setting

o   Can be directed towards employees, customers, etc

o   Most research on employee to employee violence (Schat & Kelloway, 2005)

o   Customers can be violent too (Bussing & Hoge, 2004)

·         _Generalized mistreatment:_ Rudeness, verbal attacks, invasions of privacy, bullying, etc. (Bowling & Beehr, 2006)

·         Individual predictors (Day & Catano, 2006)

o   Past history of violent behavior

o   Drug and alcohol abuse

o   Low C A or high N

·         Organizational predictors

o   Fairness

### Substance Use

·         Prohibited by Title VII of 1964 Civil Rights Act

·         14% of workforce reports using illicit drugs (Frone, 2006)

·         Most research examined consequences of using drugs OFF the job

·         Impact of substance use

o   Increased absenteeism

o   Greater frequency of accidents

o   Performance decrements

o   More job withdrawal

o   More antagonistic behavior towards others

·         Environmental predictors

o   Stressful job conditions

o   Social norms surrounding substance use in organizations

o   Social factors within workgroups and professions (Key!; Frone, 2006)

·         Prevention of substance use

o   Drug screening

§  Allows organizations to identify applicants who have substance abuse problems and may be a deterrent to those considering substance

§  Limitation: Cost and may turn off valuable employees

§  Must be able to show job relevance

o   Screen out low C

o   Conduct background checks

·         Organizational responses

o   Punishment

o   Treatment

o   Zero-tolerance policies

### Sexual Harassment

·         Unwelcome sexual advances, requests for sexual favors, another verbal or physical contact when:

o   Submission is either explicitly or implicitly a term or condition of employment

o   Submission to or rejection of conduct is used as a basis for employment decisions affecting that individual

o   Such conduct has the purpose or effect of reasonably interfering with work performance or creating an intimidating, hostile, or offensive work environment

·         Tends to be part of a general pattern of mistreatment and harassment; correlated with incivility (Lim & Cortina, 2005)

·         Quid pro quo sexual harassment

o   When employee advancement or performance is adversely impacted by refusing the sexual advances of a supervisor or other employee who has power over the focal employee

o   First two conditions in definition

·         Hostile work environment

o   No overt attempt to manipulate or threaten

o   Based on general behavior of others in the workplace

o   Vulgar comments, telling off-color jokes, etc.

o   Third condition in definition

·         Organizational response

o   Organizations are much better when they investigate such incidents objectively, rather than denying them

o   Have a clear sexual harassment policy in place

## Measurement

·         Self-report

o   Berry et al. 2012 meta show self-report may be best

§  Self-report moderately to strongly correlated with other reports (mean r = .32)

§  Self-report tend to report more CWB than other-report (more accurate?)

§  Self and other reports have similar patterns with correlates

·         Frequency scale

·         Should consider… (Bowling & Gruys, 2010)

o   Situation specific vs. generic measures

§  Opportunities to perform

§  Job-specific CWBs

o   Sub dimensions

§  Legality

§  Hostile vs. instrumental aggression

## Predictors (Berry et al., 2007; Berry et al., 2012)

·         C (-.31)

·         A (-.35)

·         N (-.20)

·         GMA (not from Berry et al., 2012)

·         OCB (-.30)

·         Procedural and interactional justice (-.30)

·         Negative affect (.30)

·         Conflict and constraints on the job (.30ish)

## Role of CWB (and OCB) in Performance Ratings

·         OCB-CWB (rho = -.32) (Dalal, 2005)

·         OCB and CWB are relatively independent aspects of performance (Spector et al., 2010)

·         Three homogenous clusters of rating policies (Rotundo & Sackett, 2002)

o   Task performance weighted highest

o   CWB highest

o   Equal and large weights to task performance and CWB

o   Rating policy cannot be predicted by demographics

·         Gender-stereotypic prescriptions matter (Heilman & Chen, 2005)

o   Performing altruistic OCB enhances favorability of men’s but not women’s evaluations

o   Withholding altruistic OCB dimensions favorability of women’s but not men’s evaluations

o   Work-related altruism is less optional for women than for men

·         Rater weights also differ by organizational culture, source, and job (Lievens et al., 2008)

o   As team-based culture increases, task performance less important and OCB more important; CWB about the same

o   Peers weigh OCB more than supervisors, supervisors weigh task more than peers; CWB weighted the same

·         Implication: Organizations should impose a performance theory, including weight for each criterion

# Dynamic Criteria

## Overview

·         Originally introduced by Ghiselli (1956)

### Definitions

·         _Dynamic criteria:_ Change in importance of criteria over time (Cascio, 2005)

·         _Dynamic criteria:_ A change in rank order of subjects’ performance over time (Steele-Johnson et al., 2000)

o   Involves examining stability of single performance measures across two of more measurement occasions

o   Changes over time in validity coefficients between predictors and criteria

·         _Stability:_ The extent to which the true value of a measure remains constant over time (Sturman et al., 2005)

·         _Temporal consistency:_ The correlation between performance measures at different points in time (Sturman et al., 2005)

·         _Test-retest reliability:_ The relationship between performance measures over time and after removing the effects of performance instability (Sturman et al., 2005)

### Three Ways in which Criteria May Change over Time (Cascio, 2005)

·         1. Changes over time in average levels of group performance

·         2. Changes over time in validity coefficients

o   _Changing task model:_ Although the relative amounts of individual ability remain stable over time, criteria for effective performance might change in importance, consequently changing the predictors

§  The importance of some abilities increases while the importance of other abilities decreases while continuing practice on a task. For early trials, cognitive factors are important and motor abilities become important for later trials (Woodrow, 1938)

o   _Changing subjects model:_ Although the abilities for individual performance remain constant, individual’s level of ability changes over time, consequently fluctuating validity

§  The amount of a given ability possessed by a given individual changes with practice, learning, or experience with the task (Adams, 1957)

·         3. Changes in rank ordering of scores on the criterion

### Potential Reasons for Dynamic Criteria (Steele-Johnson et al., 2000)

·         Subjects might change the ways they perform a task

·         The KSAOs needed to perform a task might change

·         The knowledge and abilities of subjects might change

·         Technology changes

·         Situational constraints

·         Situational strength

### The Simplex Pattern (Henry & Hulin, 1987)

·         Higher correlations among adjacent pairs of criterion measures than pairs of measures spaced further apart

## Factors Influencing Dynamic Criteria

### Temporal Bias

·         Random environmental and internal events that affect individuals and their rank order on the attribute being measured

·         Temporary events need not be the same for different individuals

·         Contribute more strongly to the correlation between measurement at time period that are relatively close together and make a diminishing contribution to the correlation between measurements taken at time periods that are widely separated

·         Occurs most strongly in situations in which individuals have some measure of control over their environment

·         When individuals are very similar and the environment is very homogenous, the simplex pattern is reduced or non-existent

### Temporal Stability of Cognitive Abilities and Related Constructs

·         General cognitive ability is relatively stable through middle age and only declines later in life

·         More specific abilities vary in their stability

·         Performance on intellectual tasks that are speeded, performance based, or involving fluid intelligence show greater decrements at younger ages

·         Intellectual tasks that are un-speeded, verbal, or involving crystalized intelligence remain stable longer, not showing decrements until the seventies

### Task Complexity (Campbell, 1988)

·         Any task that increases information load, information diversity, or rate of information change contributes to complexity

### Task Consistency

·         The extent to which the information processing demands of different tasks are consistent or inconsistent

### Job Complexity

·         Number of tasks, relationships between task, and average task complexity

### Job Consistency (Murphy, 1989)

·         Specific tasks, responsibilities, and expectations of individuals working in a particular job may change systematically as a function of job tenure

·         _Transition stage:_ Tasks are new due to hire or change

o   Cognitive ability is most influential on performance because the employee must gather new information and make judgments without the benefit of experience

·         _Maintenance Stage:_ Dispositional factors more influential because major tasks and situations are not novel – periods of low levels of change – when job procedures and/or tasks are mastered

·         All jobs require transition stages, but frequency and duration of transition stages increases as job complexity increases

### Changes in Technology and Changes in the Work Process

·         Changes made to the way work is done resulting from changes in available technology

### Situational Constraints

·         Create a ceiling effect in performance for high ability individuals

·         Limit the range and variance of observed performance

·         Attenuate correlations between individual differences (e.g., ability motivation) and performance

### Situational Strength (Mischel, 1977)

·         Strong situations: Psychological situations (i.e., stimuli, treatment) are powerful to the degree that they lead everyone to construe particular events in the same way

## Test-Retest Reliability (Sturman et al., 2005)

·         Reasons for lack of test-retest reliability

o   The rater may become distracted, misunderstand items, or rush through items

o   Rater and ratee mood

o   Environmental factors such as situational constraints, opportunity to perform, opportunity to observe

·         Meta-analytic results

o   Test-retest reliability ranged from .53 to .61 (performance ratings)

§  As time lag between measures increased, reliability decreased (simplex pattern)

o   Objective measures and greater complexity were associated with decreased reliability

§  Objective measures of performance were LESS reliable over time (especially for highly complex jobs)

§  Subjective measures of performance for low complexity jobs were the most reliable

o   Impossible to estimate a single true reliability of job performance, because value is contingent upon the time interval used and job complexity

·         Implication: Job analysis conducted with SMEs early in their tenure may have different results from those by SMEs later in their tenure

# Rating Sources

## Types of Sources

### The Supervisor

·         Feedback from supervisors is more highly related to performance than any other source (Becker & Klimoski, 1989)

·         Advantages

o   Supervisors are typically responsible for organizational rewards/punishments

o   They are familiar with objectives

o   More reliable than peer ratings (Viswesvaran et al., 1996)

§  Maybe not…found a much lower estimate in Hoffman et al., (2010)

·         Disadvantages

o   Not all regularly and directly observe their employees

o   For those organizations with flexible work arrangements, supervisors may not be in a good position to observe the workers performance on a regular basis (Borman, 1991)

### The Peer

·         Peer nominations, peer ratings, peer rankings

·         Usefulness may be greatest in team environments (Hedge & Borman, 1995)

·         Advantages

o   Peers may be more “in touch” with an employee’s day-to-day functioning

o   Can identify the necessary characteristics of a good employee in a very job-specific way

o   Peers may have more opportunity to realistically observe than supervisors

·         Disadvantages

o   Perceived friendship bias can artificially build up or tear down individuals

### The Self

·         May be especially important for employees working in isolation

·         Advantages

o   Opportunity to participate in one’s own appraisal can be motivating

·         Disadvantages

o   Tend to be most lenient

§  Peer and manager ratings related to performance appraisals; self-ratings were not (Beehr et al., 2001)

o   Least correlated with judgments from others (Harris & Schaubroeck, 1988)

### The Subordinate

·         Advantages       

o   Most directly experience ineffective job skills on the part of a supervisor

o   Better quality when used for development rather than administrative purposes

·         Disadvantages

o   Fear of retribution or political concerns

### The Consumer

·         Advantages

o   Ratings are useful for positions that require high degree of contact with the public, such as sales

·         Disadvantages

o   Cannot expect to know, understand, or respect organizational objectives

### Electronic Performance Monitoring (Hedge & Borman, 1995)

·         Employees can be monitored in many ways (e.g., phone monitoring, video camera, computer monitoring)

·         Advantages

o   Provides a concrete, accurate performance measurement

o   Managers can use to motivate employees by providing incentives and rewards

·         Disadvantages

o   Can be de-motivating if employees feel they lose autonomy

o   May be seen as an invasion of privacy

## Multisource Feedback

### Overview (Borman, 1997)

·         Involves generating performance evaluations on target from multiple sources

·         i.e., 360 method

·         Feedback for development is a frequent application

·         _Multi-task multi-rater approach:_ Matrix that assesses the degree of inter-rater agreement within rating dimensions and the ability of raters to make distinctions in performance across dimensions

·         Ratings from both the self and others are related to performance outcomes (Atwater et al., 1998)

#### Why Gather Multiple Sources?

·         Ratings from both the self and others are related to performance outcomes (Atwater et al., 1998)

·         Feedback from constituencies other than supervisors may provide new information that captures performance in multiple roles (Atwater et al., 2002)

o   May also reinforce and support supervisor feedback, making it more difficult to discount negative feedback as a biased viewpoint

o   360 can be used for developmental purposes (in fact little support for improvement of the bottom line)

·         Everyone is doing it

o   Most valid systems have more than one rater (Bernardin & Beatty, 1987)

o   Most Fortune 500 firms use multisource feedback (Conway et al., 2001)

·         Psychometrically it’s OK – Measurement equivalence across rater sources and performance dimensions (Diefendorf, 2005)

### Two assumptions (Borman, 1997)

·         Multiple sources of ratings offer at least somewhat unique data on ratee performance

o   Each rating covers a different portion of the criterion space

o   Differences in perspectives should NOT be treated as error (Tornow, 1993)

·         Having additional rating sources providing evaluations yields incremental validity over a single source

### Hypotheses for Why Ratings Differ by Source (Borman, 1997)

·         Raters at different levels use different dimensions or weight dimensions differently as a basis for evaluating performance (e.g., inter-rater agreement within organizational level tends to be greater than agreement across levels)

o   NOT empirically supported

·         Raters at different levels actually observe different performance related behaviors in target ratees

o   Little empirical evidence either way

·         Ratings may reflect different rater goals, especially for high stakes (DeNisi & Sonesh, 2011)

### Source Agreement

·         Intrarater reliability is higher than interrater reliability (Viswesvaran et al., 1996)

o   Correlations of ratings by the same level of raters was higher (.72) than those from different levels (.54)

·         Better interrater reliability for simpler, non-managerial jobs (Conway & Huffcutt, 1997)

o   Less reliance on heuristics, recency, primacy,

·         Self-ratings tend to be least correlated with judgments from others (Harris & Schaubroeck, 1988 meta)

o   Self & Peer = .36, self & supervisor = .35, peer & supervisor = .62

o   Conclusion also supported by Ostroff et al., (2004) (.18, .16, .39, respectively)

o   Also tend to be least reliable, smallest correlations with other constructs, least construct validity (Dunning et al., 2004)

o   Why?

§  _Egocentric bias:_ Self-ratings are biased in some ways

§  _Differences in org level:_ Different levels weight performance dimensions differently

§  _Observational opportunities:_ Peers have opportunities to realistically observe coworker performance

·         Individual characteristics and contextual factors impact self-other agreement (Ostroff et al., 2004)

o   Significant portion of variance in self-other ratings accounted for by asset of background & context variables

o   Women, whites, younger management, those with less experience, those with higher education all had better self-other agreement

o   Non-whites, those with more managerial experience, those who supervisor more employees tend to over-rate themselves

o   Lower self-ratings for males and lower education

### Incremental Validity

·         Peers and subordinates ratings provided incremental validity in objective performance over supervisor ratings (Conway et al., 2001)

·         Raters base ratings on how rewarding their performance is (Conway et al., 2001):

o   Peers and subordinates correlated positively with getting along variables (A and affiliation)

o   Supervisor ratings correlated positively with getting ahead variables (GMA, dominance, achievement, potency)

·         Personality ratings made by others increment over and above self-ratings in predicting performance (Mount et al., 2004

·         Average of supervisor, peer, and subordinate ratings can predict performance in an assessment center as well as supervisor ratings (Atkins & Wood, 2002)

### Issues with Source Variability

·         In order to pool raters’ data within level, need to demonstrate a source effect

·         Hoffman et al. (2010); Hoffman & Woehr (2009) say it is wrong to neglect rater source effect

o   Past studies that did not find source effects either did not properly model all sources of variance or used inappropriate CFA analytic models (Hoffman et al., 2010)

o   Found source effects are alive and well after re-analyzing data sets

o   Structure of multiple source ratings can be characterized by idiosyncratic rater, source, dimensional performance, and general performance

·         Murphy (2008); Murphy & DeShon (2000) argue agreement between raters does not represent reliability; issues with construct validity of ratings

·         Viswesvaran & Ones (2000) do not acknowledge source variance as valid because they think interrater reliability is the basis of our science

o   Each individual has a true score

o   When raters disagree, it is because their observations are unreliable

o   Correcting for this unreliability will get us closer to the true score

o   Interrater reliability is an appropriate estimate of rating reliability (Ones et al., 2008; Schmidt et al., 2000)

# Methods for Assessing Performance

·         We cannot often directly measure performance

o   Performance is not the same as measurement of performance

·         Many potential sources of error in performance ratings (to be discussed)

·         Two ways to reduce error in performance ratings (again…to be discussed)

o   Rater training

o   Seek more objective performance measures (but these come with their own host of issues, a primary one being that they are not under the employee’s control)

## Steps for Raters (Borman, 1991)

·         Conduct an organized search for ratee performance-related behavior

·         Translate these behavior observations into evidence pertinent to assessing ratee performance on each dimension

·         Make accurate judgments about ratee effectiveness levels on each dimension

## Eight Methods of Assessing Performance (Murphy, 1989)

·         Paper pencil tests

·         Job skills tests

·         Onsite hands on testing

·         Offsite hands on testing

·         High fidelity simulations

·         Symbolic simulations

·         Task ratings

·         Global ratings

·         Two most common methods are ratings of employee performance on specific tasks, and ratings of overall performance on the job

## Objective and Subjective Measures

·         NOT interchangeable with one another.

·         Correlations between objective and subjective ratings as provided by:

o   Supervisors (.35; Bommer et al., 1995)

o   Peers (.29; Conway et al., 2001)

o   Subordinates (.25; Conway et al., 2001)

·         Use both if you can! (Borman & Smith, 2012; Wall et al., 2004)

·         Subjective and objective measures of company performance are generally equivalent with a range of independent variables; convergent/discriminant validity supported (Wall et al., 2004)

### Objective Measures (Spector, 2003)

·         Count the number of behaviors or amount of work that is produced

·         Examples: days absent/year, number of incidents at work, sales

#### Turnover (can be useful)

·         Must know reason (voluntary vs. involuntary)

·         Voluntary turnover not necessarily bad for poor performers

·         Voluntary neg related to job performance (r = -.25; Barrick & Zimmerman, 2009)

o   Findings are not consistent

o   Complex because both high and low performers are likely to quit (Trevor et al., 1997)

·         May be able to predict using biodata – number of family/friends at the org, employee referral, tenure at most recent job; Barrick & Zimmerman, 2005)

#### Absences (not very useful)

·         Limitations

o   Voluntary/involuntary get lumped together

o   Unstable

o   Low base rate, missing data points in personnel records (Iverson & Deery, 2001)

o   Serious skewing of distributions

o   Non-work inducements might cause absences

#### Sales (may be useful if applied with care)

·         Gap between actual sales and quota may be useful, if quota is thoughtfully determined

·         Limitations

o   Environmental factors beyond control of the salesperson

§  Can try to adjust for such factors, but need a good strategy

o   Deficient (e.g., doesn’t measure customer relations)

#### Production Rates (useful in limited settings)

·         Can track both productivity quantity or quality

·         Limitation: Issues with standardization

o   All use the same equipment?

o   All subject to the same standards/quotas?

o   Periodic incentives to increase production?

#### Jobs and Salary Levels (can be useful)

·         With thoughtful correction, can be reasonable index of employee worth

·         Limitations

o   Organizational politics can influence this

o   People enter organizations at different levels and salaries

o   Situational factors should be considered – opening of jobs at higher level, market value of specialty

#### Work Samples (useful for selection research and training programs)

·         Measure of perf on a structured task that is directly reflective of the types of behaviors required on the job

·         Benefit: High fidelity, but for maximal performance

·         Limitations

o   Not so great for typical performance

o   Time consuming, labor intensive, expensive

o   May be equipment constraints

·         Need to analyze the job to pick the best tasks (otherwise deficient; Lance et al., 2000)

o   Most widely or frequently performed tasks

o   Select tasks with ranges of difficulties

o   SMEs should review and approved

·         If properly trained, raters can make valid and unbiased judgments (Lance et al., 2000)

·         Correlates with GMA .38 (Roth et al., 2005)

·         See more in “Work Sample and Performance” section

#### Job Knowledge Test (most useful in training programs)

·         Define the job domain with an exhaustive list of tasks and use expert judgment to pick the most important ones for item writing

·         Benefit: Inexpensive alternative to work samples

·         Limitation: Not useful for tasks requiring skills and operations

#### Disciplinary Cases (useful in highly structured orgs)

·         Index of troublemaking behavior detriment to individual performance or org effectiveness

·         Limitations

o   All units/supervisors may not have the same policies

o   Low base rate

·         Some evidence of construct validity for self-report disciplinary actions

#### Benefits

·         Easy to interpret meaning of objective measures

·         Quantitative nature makes it easy to compare performance of individuals in the same job

·         Can be tied directly to org objectives

·         Can often be found in org records, so don’t need special systems

#### Limitations

·         May not be appropriate for all jobs

·         Not always obvious what number is considered satisfactory

·         Data might be contaminated and inaccurate

·         Tend to focus on specific behaviors, which may be deficient

·         Focuses on quantity, not quality

·         Measures may not be under the control of the individual

·         Not independent from judgments (e.g., type of turnover; McElroy et al., 2001)

·         Objective measures are almost always deficient, contaminated, or both (Borman, 1991)

### Subjective Measures (Cascio, 2005)

·         Ratings by people who should be knowledgeable about the person’s performance

o   Depend on human judgment and consistency

o   Usually supervisor

o   Somewhat quantifiable

o   Behaviorally focused

·         Limitation: May be contaminated

·         Can be absolute or relative (e.g., ranking)

## Relative and Absolute Rankings

### Relative Rankings

·         Comparisons made among a group of ratees, typically performed with rankings

o   Lack specificity and are not consistent over time

·         _Simple ranking:_ A rater orders all ratees from highest to lowest

·         _Alternation ranking:_ A rater picks the best, the worst, then the second best, then…

·         _Paired comparisons:_ Compare each person to each other person. Pick the best of the two. Add the total number of times the person was selected

·         _Forced distribution:_ Employee performance is forced into a distribution, so X% are within each quartile, for example. Controversial because it may (or may not) accurately reflect level of performance.

### Absolute Ratings

·         Ratee is described without reference to others. This type of rating is more complete, but also more time consuming.

## Rating Formats

### Graphic Rating Scale

·         Most popular

·         Used to assess individuals on several dimensions of performance

·         Focuses on characteristics or traits (e.g., dependability) of the person or performance

·         Continuum of performance from high to low values

·         Free rater from direct quantitative terms

### Narrative Essays

·         Describe strengths and weaknesses in writing, which give detailed feedback to the ratee

·         Limitation: Unstructured nature makes comparisons difficult

### Behavioral Checklist

·         Describe statements that the rater picks that best describe the ratee

·         Benefits:

o   Easy to use and understand

o   Often reliable

·         Limitations:

o   Hard to give diagnostic feedback

o   No specific behaviors are given

### Forced-Choice Checklist

·         Two choices of equal desirability

·         Benefit: Rater cannot distort ratings

·         Limitation: Raters are often resistant

### Critical Incidents

·         Reports by knowledgeable observers of things employees did that were especially effective or ineffective towards accomplishing a goal

·         Often do not lend themselves to quantification

### Behavioral-Focused Rating Forms (Spector, 1993)

·         Concentrates on specific instances of behavior that the person has done or could be expected to do

·         A form must be developed for a specific job or family of jobs.

·         To create a behavioral-focused form:

o   Must be developed for a specific job or job family

o   Step 1: JA to define performance dimensions

o   Step 2: Develop descriptions of effective and ineffective job performance from critical incidents

o   Step 3: Have knowledgeable judges place descriptions into job dimensions

o   Step 4: Have knowledgeable judges rate effectiveness of descriptions

o   Step 5: Pilot test to check inter-rater reliability

#### Behaviorally Anchored Rating Scales (BARS) (Smith & Kendall, 1963)

·         Response choices are defined in behavioral terms

·         BARS response choices are behaviors whereas graphic rating forms ask for how well the person performs along the dimension in question

·         When developing use behavioral-focused form step, but also check for agreement about effectiveness levels. Use items as behavioral anchors for your rating scales (usually 3: high, medium, low effectiveness)

#### Mixed Standard Scale (MSS) (Blanz & Ghiselli, 1972)

·         Provides rater with a list of behaviors that vary in effectiveness.

·         For each statement, the rater indicates if the ratee is better, fits, or is worse than the statement.

·         Statements are presented in random order

#### Behavior Observation Scale (BOS) (Latham & Wexley, 1977)

·         Items based on critical incidents.

·         Raters are asked to indicate the amount of time the employee engages in each behavior

o   Development of behavior-focused forms

#### Behavior Summary Scale (BSS) (Borman, 1979)

·         More general anchors at each of the three of four effectiveness levels

·         Summarize all of the behavioral anchors representing the effectiveness level

#### Computer Adaptive Rating Scales (CARS) (Borman et al., 2001)

·         Paired comparison format using an iterative, computer-adaptive format to select items

·         Benefits:

o   Reliable

o   Low standard error of measurement

o   High validity

o   More accuracy than other methods

·         Reasons for benefits:

o   More behavioral information and items presented to raters

o   Statements directly targeted to rater

o   People make better judgments when comparing two items

o   No points of numbers used, so more behavioral focused

o   Does not assume a true interval scale

o   Only focuses on behavior, not ratings

#### Frame of Reference Scales (Hoffman et al., 2012)

·         Goal is to create the same frame of reference for rating performance without training; info communicated in the scale

·         Presents definition of performance and behavioral examples in the scale

·         Behavior CIs used as examples, rather than anchors

·         Allows for multiple ratings on a competency

·         Shown to be just as good as FOR training for rating accuracy

### Differences between Formats (Borman et al., 2001)

·         Minimal differences in errors, reliability, or validity between formats.

·         No one technique is superior to any other

·         Some require more time and others are less quantifiable

·         At best 4-8% of variance in performance ratings are accounted for by proposal format. Called for a moratorium on format research (Landy & Farr, 1980)

# Work Sample and Performance Testing

## What do they Measure (Calinan & Robertson, 2000)
- Performance factors unrelated to intelligence
- Work techniques and methods (past experience)
- Tacit knowledge (practical knowledge about what to do and when you do it)
- Natural interaction effects (interaction of skills and abilities)
- Motivation and desire for the job
- Maximal performance
- Based on the assumption that past behavior is the best predictor of future behavior

## Benefits of Work Sample Tests (Calinan & Robertson, 2000)
- Good predictors of job performance (multifaceted)
- Substantially less adverse impact than cognitive ability tests
	- (.38; Schmitt et al., 1996)
- Elicit positive applicant reactions (provide a realistic job preview)
- Fewer lawsuits

## Types of Work Sample Tests (Calinan & Robertson, 2000)
### Hands-On Performance Tests
- Psychomotor tests
	- Validity = .39 (Robertson & Kandola, 1982)
	- Can only assess individuals with experience in a similar job

### Trainability Tests
- Job learning or trainability tests are work samples that inclue a structured and controlled period of learning prior to the actual task performance
	- Allows the assessment of potential candidates with no experience or prior training to benefit from training to be hired
	- Mini-course approach – Use a sample of training to predict performance on a full training session

### Situational Tests

·         Applicant describes how s/he would behave in a given situation

·         Can be interview, paper/pencil, computer, or video based

### Job Knowledge Test

·         See below

### Assessment Center

## Dimensions for Comparing Work Samples (Calinan & Robertson, 2000)

·         _Bandwidth:_ Degree to which the entire job performance domain is represented

·         _Fidelity:_ The degree to which tasks and content mirrors actual job situations

·         _Specificity of tasks:_ Degree to which the task is job-specific versus specific to jobs at the same level

·         _Necessary experience:_ Degree to which the task is appropriate for applicants with no prior experience on the job

·         _Type of task:_ Type of behavior being measured (psychomotor, verbal, social)

·         _Type of presentation:_ Behavioral, verbal, written

## Validity (Roth et al., 2005 Meta)

·         Observed mean correlation between work sample tests and measures of job performance corrected for attenuation (.33)

·         Higher than Schmidt & Hunter (1998)

·         Incremental validity of .06 above GMA

## Work Samples vs. Job Knowledge Tests

### Work Samples (Borman, 1991)

·         High face validity

·         Choose tasks that will generalize to job performance

·         Score the product or the process

o   Should focus on the work sample

o   Focus on the process of performing a task or the product that comes from completing the tasks

·         Unscoreable or difficult to score tasks should be avoided

·         Measure maximal rather than typical performance

### Job Knowledge Tests

·         Not suitable for testing tasks that require skills and operational ability

·         Used primarily as criteria to assess the outcomes of training

·         Paper and pencil tests may not be appropriate for all jobs

·         Low reading level may prevent some from passing despite having the knowledge

# The Process of Making Ratings (And All that Can Go Wrong)

## Rating Steps (Spector, 2003)

·         Observing performance

·         Storing information about performance

·         Retrieving information about performance from memory

·         Translating retrieved information into ratings

## Two Types of Cognitive Process Models (Borman, 1991)

·         Rating processes research can show us how ratings are made

·         Allows us to intervene and reduce errors, biases, and inaccuracies

### DeNisi et al., (1984)

·         Performance evaluations typically involve observing performance storing the information, retrieving the information at a later time, then rating the performance of the individual

·         Same as Spector, 2003

### Feldman (1981)

·         Suggests a “cognitive process” approach to the study of performance appraisal

o   Appraisal context assumes that the supervisor is performing several cognitive tasks

o   Emphasizes the encoding step and talks about categorizations.

#### Recognize and Attend to Relevant Information about the Employee

·         Automatic process of “consistent mapping” where a given stimulus is always a target or distractor (e.g., race, gender)

·         An employee’s behavior that is consistent with the supervisors expectations will be noted and stored automatically

·         When a behavior departs from expectations, conscious attentions and recognition processes are engaged

#### Information is Stored and Organized for Future Use; New Info is Integrated

·         Rater may use schemata (frames of reference categories) such as stereotypes (beliefs about members of a group) or prototypes (standard to help interpret and organize experiences)

·         Categorization

·         Enables people to process larger amounts of data despite inherent limitation on storage capacity

·         Once a supervisor categorizes an employee, he/she recalls and attends to prototype consistent stimuli

·         Sometimes the prototype is based on general stereotype

·         Situational factors influence the salience of given categories

#### Controlled Categorization

·         A rater has to re-evaluate the category assigned to the employee when something the employee does is very discrepant from the prototype

·         Likely when the person and/or situation is new and or when an event exceeds a discrepancy threshold

·         Explained by attribution theory

o   _Fundamental attribution error:_ Underestimate situational factors and overestimate dispositional factors

o   _Causal attribution differences:_ Emphasize situational factors of observers, personal dispositions of the actor

o   _Hedonic relevance:_ Tendency to see actions having more affective consequences for the observer as more dispositional than other actions

o   _Affective relationships attribution_: Good actions are due to the person, bad to the environment (but only for individuals that you like!)

#### When Judgments are Required, Relevant Information is Recalled

·         _Recall:_ Behavioral information is held in mind for a short period of time, and then it is included in the predetermined category

·         _Representativeness heuristic:_ A is like B

·         _Availability heuristic:_ The ease with which the event is brought to mind

·         _Information search:_ Supervisors may purposely seek out new information to confirm their impressions, however they will tend to see what they expect and not see the unexpected

·         _Information seeking and recategorization:_ If new information does not require recategorization of an individuals, memories will be constructed to support this

#### Information is Integrated into Summary Judgments

·         _Cognitive integration:_ The outcome is a categorization or belief statement or prediction of a behavior

o   Clinically combined in thoughts

·         _Evaluative integration:_ The outcomes are based on the most salient categories and the final evaluation is a weighted average of the separate category-based evaluations

o   Use thoughts on each dimension and mechanically combine

## Mental Shortcuts

·         Individuals often use stereotypes or schemata (Borman, 1987) to assist with the process.

o   May allow raters to make accurate judgments in performance evals (Lord & Maher, 1989), but can also trigger rating errors

·         Raters are nearly unable to provide completely accurate ratings (DeNisi & Williams, 1988; Feldman, 1981)

·         Sometimes managers give lenient ratings to maintain group harmony (Longenecker et al., 1987)

### Common Rater Heuristics (Borman, 1991)

·         _Schemata:_ Categories of frames of reference that help interpret and organize their experience. Used by raters to make judgments about groups

·         _Prototype:_ Highlight modal or typical features of a category

·         _Stereotype:_ Beliefs about a certain group of people

·         _Scripts:_ Events or event sequences that are remembered as being representative of a person’s actions

### Personality and Social Concepts

#### Implicit Personality Theory (IPT) (Heslin et al., 2005)

·         Ratings made based on assumptions about how behaviors covary in people and the correctness of those assumptions.

o   _Entity Theorists:_ Personal attributes are fixed

o   _Incremental Theorists:_ Personal attributes are relatively malleable

·         Causes correlations between performance dimensions to be inflated and to conform to evaluator’s theory of behavior

o   Entity theorists less likely than incremental theorists to appraise people based on performance once they have formed an impression

o   Can change entity theorists to incremental through training

#### Personal Construct Theory (Kelly)

·         Personal content categories used to organize and simplify information.

·         Used to judge events and predict future behavior

#### Folk Theories

·         Performance constructs used by persons familiar with the job to judge between effective and ineffective behaviors

·         Lay theories of job performance

#### Attribution Theory

·         Consistent behaviors are more likely to be dispositional factors than inconsistent behaviors

·         Unexpected performance outcomes attributed to luck/chance

·         Behavior that matches expectation is dispositional; incongruent behavior is situational

·         _Fundamental attribution error:_ My behavior is situational, yours is dispositional

#### Interpersonal Rater Characteristics (Borman, White, & Dorsey, 1995)

·         Looked at interpersonal rater characteristics in addition to GMA, job knowledge, and task proficiency

·         Findings

o   13-17% of supervisor ratings attributed to ability, job knowledge, and technical proficiency

o   Variance explained increases to 28% when including ratee dependability, trustworthiness

o   Peer ratings were influenced by ratee personal characteristics than supervisors

## Types of Rater Errors

·         _Distributional error_: Rater tends to rate everyone the same

o   Incorrect representations of performance distributions across employees

o   Can occur in means and variances

o   _Leniency error:_ Rater rates everyone at the favorable end

o   _Severity error:_ Rater rates everyone at the unfavorable end

o   _Central tendency error:_ Rater rates everyone in the middle of the scale

o   Can be resolved with a forced distribution, requiring rankings, encouraging raters to provide feedback, increasing rater motivation to be accurate by holding the rater accountable

·         _Similar to me error_: Unwanted projection of rater’s own personal characteristics on the ratee

·         _First impression error_: Rater allows early experiences with a ratee to be weighted more than they should be

·         _Systematic distortion_: Errors that are made based on assumptions about what behaviors should go together instead of the actual co-variation of behaviors

·         _Halo effect_: Rater gives individual the same rating across all rating dimensions despite differences in performance across dimensions

o   Reasons for halo (Lance et al., 1994)

§  Increased memory demands

§  Conceptual similarity among rating categories

§  IPT: Raters categorize employees according to prototypes

o   Three models of halo (Lance et al., 1994)

§  _General impression model:_ General impression influences ratings on dimensions

·         Supported as the model that explains halo error

·         Suggests halo should be defined as the influence of a rater’s general impression on rating for specific ratee dimensions

§  _Salient dimension model:_ Halo is caused by one or more salient dimensions influencing ratings on other dimensions

§  _Inadequate discrimination model:_ Halo is caused by a failure to distinguish among different dimensions of performance

o   Also see Viswesvaran et al., (2005)

§  Halo is real! – inflates performance ratings

§  More halo in peer ratings than supervisor ratings

·         Remember rater errors may not be errors at all, may be accurate rating effects (Hakel, 1980)

o   Do not use rating effects as indirect measures of accuracy (Sulsky & Balzer, 1988)

o   Error measures are at best weakly correlated with direct accuracy measures; error and accuracy are two different things! (Murphy & Balzer, 1981)

·         Other random rater tidbits

o   Have observation and recording done by one assessor, and evaluation done by an independent assessor; as opposed to one individual doing everything

o   More consistency in the behavior of middle-level performance than there is in behaviors of high or low level performers

o   Raters more likely to recall overall impressions of ratees

## Rater Accuracy

### Components of Accuracy (Cronbach, 1955)

·         Each expresses a different portion of the distance between rater ratings and true scores (expert ratings)

·         _Elevation:_ Grand mean

·         _Differential elevation:_ Differential mean effect of ratees; relevant to overall performance rating

·         _Stereotype accuracy:_ Differential main effects of dimensions

·         _Differential accuracy:_ Differential ratee x dimension interaction; relevant in placement and giving feedback to ratees

### Borman’s Differential Accuracy (1974)

·         Based on correlating a rater’s rating for each dimension with the corresponding true scores across ratees, followed by averaging the correlations across dimensions

o   Not sensitive to distance between ratigns and true scores

o   Significantly related to Cronbach’s DE and DA

·         Generally various accuracy measures are not equivalent, making it difficult to integrate accuracy research (Sulsky & Balzer, 1988)

o   Various ways of estimating true score

o   If experts are involved, still need to establish rating reliability and validity

o   Also need to calibrate experts

·         May not always be necessary to establish rater accuracy (e.g., rank ordering for promotion, a low DE does not necessarily mean raters did a good job)

## Restriction of Variabiltiy of Performance

·         For a variety of reasons, variability in performance within organizations is often restricted

·         _Artifactual restriction:_ Results from errors in performance ratings or performance measurement system

·         _True restriction:_ Measures of performance are relatively accurate but there is a true lack of meaningful variation in actual job performance

·         Four reasons for variance restriction (Peters & O’Connor, 1988)

o   Organizations may have very low performance standards

o   Organizations vary in the degree to which they value high levels of individual job performance

o   The degree to which organizations excuse employees for low levels of performance

o   Variation in organizational resources

·         Actual performance levels may also be restricted due to selection and retention processes (ASA; Schneider, 1987)

o   Most organizations require employees pass through rigorous screening before they are hired

o   This limits the variation in skill and ability among employees

o   Employees who perform poorly or who do not fit well with the culture often leave voluntarily

# Trying to Control and Eliminate Rater Bias (Mostly Rater Training)

## Types of Rater Training (Woehr & Huffcutt, 1994)

### Rater Error Training

·         Familiarizes raters with errors and teaches them to avoid using these rating patterns

·         May result in less accurate ratings (Hedge & Kavanagh, 1988)

·         Moderately effective at reducing halo; less effective at reducing leniency

### Performance Dimension Training

§  Familiarizing the raters with the dimensions on which performance is subsequently related to the observation of performance

§  Typically accomplished by having raters review the rating scale

§  Moderately effective at reducing halo but increases leniency

### Frame of Reference Training (FORT)

·         Train raters to share and use common conceptualizations of performance when providing their ratings

·         Raters are given specific examples of behavior that would represent various levels of performance for each dimension

·         The best (Woehr & Huffcutt, 1994)

o   Decreases halo and leniency error; small increases in observational accuracy; best for increasing rating accuracy (d = .83) Pulakos (1986)

o   Increases accuracy, develops relatively stable performance schemas (Gorman & Rentsch, 2009)

o   Increases, reliability, criterion-related, and construct validity of assessment center compared to controls (Schleicher et al., 2002)

§  Best approach for improving accuracy

### Behavior Observation Training (BOT)

·         Focuses on the observation and recording of behavioral events as opposed to information integration and evaluation

·         Assumption is that better observation of behavioral information will result in higher levels of recall or recognition

·         Medium to large positive effect on rating accuracy and observational accuracy

·         Combining FOR and BOT improves behavioral accuracy but not rating accuracy (Noonan & Sulsky, 2001)

o   FOR + BOT accuracy is the same as FOR alone

## Benefits and Limitations of Rater Training (Cascio, 2005)

·         Benefits

o   Improves the observation skills of raters by teaching them what to attend to (also Noonan & Sulsky, 2001)

o   Reduces or eliminates judgmental biases

o   Improves the ability of raters to communicate performance information to ratees

o   Motivates raters to use skills and knowledge they have acquired in training (Noonan & Sulsky, 2001)

·         Limitations

o   Costly to develop and implement

## Other Ways to Improve Ratings

·         Design better performance analysis forms that will be resistant to these problems

o   BARS and MSS help because they focus on specific behaviors rather than traits

o   More concrete and require less idiosyncratic judgment

# Miscellaneous Issues in PA

## Ways to Increase Employee Acceptance (Cascio)

·         Only one in ten employees believes that their firm’s appraisal system helps them to improve performance (Pulakos, 2004)

o   Challenging to implement - serve multiple purposes, politically charged, legal concerns

o   State of science outpaced state of practice

·         Frequent evaluation

·         Supervisors are familiar with work

·         Employees are allowed to express their own view

·         New performance goals are set

## Ways Supervisors can Maximize Effectiveness (Cascio)

·         Engage in frequent communication with employees

·         Judge own performance first

·         Appraisal training

·         Encourage subordinate preparation and participation

·         Judge performance, not personality

·         Be specific

·         Be an active listener

·         Avoid destructive criticism

·         Set mutually agreeable goals and evaluate progress towards goals regularly

·         Make organizational rewards contingent upon performance

## Impact of Technology on PA

·         Easier to monitor objective productivity

·         “Big data” allows for collection of lots of information; may be able to better capture dynamic performance

·         Wearable technologies help to capture performance as it happens

·         Could monitor work performance at home

·         Helped to build performance management systems that can provide reminders, instructions, be used to conduct a 360, etc.

·         Issues with privacy and dehumanization

·         Still has concerns about construct validity and capturing the performance domain

## Legal Issues in PA

·         Illegal to discriminate on the basis of non-performance related factors such as age, gender, mental or physical ability, or minority status in the US

·         Subjective measures are especially likely to evoke legal challenges

·         Six components of a legally defensible PA system (Barrett & Kernan , 1987)

o   Perform JA to define dimensions fo performance

o   Develop rating form to assess dimensions

o   Train raters in how to assess performance

o   Have higher management review ratings and allow employees to appeal their evaluations

o   Document performance and maintain detailed records

o   Provide assistance and counseling to poor-performing employees prior to taking actions against them

·         PA systems that based on JA, that gave written rater instructions, offered employees input, and used multiple raters were far less likely to result in an organization losing a case (Werner & Bolino, 1997)

·         Fairness is important! It can impact job attitudes and turnover intent, even if ratings are low

## Examples of PA that Companies have Used (DeNisi & Pritchard, 2006)

·         Management by objective

o   Effectiveness is uncertain

·         360 feedback

o   Costly, effectiveness uncertain

·         Balanced scorecard

·         Programs that emphasize performance management (with appraisal as input)

·         Productivity measurement and enhancement system (ProMES; Pritchard et al., 2008)

o   Intervention aimed at enhancing the productivity in work units within organizations through performance measurement and feedback

o   Based on NPI theory – People are motivated by the anticipation of how their efforts will lead to satisfying their needs

o   Design teams -> develop objectives -> identify indicators -> reviewed and approved by upper management -> operationalize result-to-evaluation connections (contingency graph) -> get approval -> set minimum and maximum levels realistic for each indicator -> derive effective score for the levels -> finalize the contingency -> put into use -> collect data on indicators, feedback report given to each member after each performance period -> identify ways to improve

o   Key features

§  Participation and transparency - > validity perceptions - > openness to feedback

§  Goal setting

§  Team-based

o   Good results!

§  Large effect size (1.16 SD)

§  Improvements last over time

§  Method works in different settings

## Future Issues and Challenges

·         Objective measures are often deficient, but subjective often have contamination. Need to improve both types.

·         Applying PA systems across countries where customs/values differ

·         Convincing the org stakeholders to have complete and unbiased PA

o   Sound system is less likely to be challenged in court

o   Sound system is likely to be more effective in meeting objectives

# Articles to Know

## Farr & Levy, 2007

·         Describe the history of PA research

·         Started in the 1930s with appraisal in the military

·         Early research focused on rating formats, developing rating scales, and examining rater error and bias

·         In 1980s paradigm shift to focusing on cognitions and social context

o   Also some research on formats that are fancier, using computers (e.g., CARS)

## Austin & Crespin, 2006

·         Grand daddy review of PA research on the criterion problem

·         Valdiation for scientific explanation is being fruitfully applied to criterion measures

·         Values remain a continuous issue

o   E.g., OCB – is it properly defined and measured? How do we incorporate it into PA?

·         Research-practice interface requires attention

·         Multilevel models have had a positive impact

·         Rebalance attention to performance ratings accounting for stakeholders as well as psychometric excellence

·         Need more focus on technology in the workplace

o   E.g., criterion theory for cyber working

## Deming, 1986

·         Had “four charges” against current performance appraisal practices

·         Performance may be due to org constraints

o   Makes PA unfair

o   Due to faults in the system or faults in a special event or subgroup

·         Promote behaviors that compromise quality

·         Create a band of discouraged workers who cease trying to excel; fault lies in relative rankings and forced distributions

·         Rob workers of pride in workmanship

## Ghorpade & Chen, 1995

·         Why performance appraisal is inevitable

o   It’s a way of assessing whether the org is getting what it wants out of the employee

o   It is essential for legal issues

o   PA allows us to account for individual differences in the quality of work

·         Good PA systems are observable, measurable, job related, important to job success, controllable, and practical

·         Criticisms of PA practices (Deming, 1986)

o   Performance may be due to org constraints

o   Promote behaviors that compromise quality

o   Create a band of discouraged workers who cease trying to excel; fault lies in relative rankings and forced distributions

o   Rob workers of pride in workmanship

·         Ghorpade and Chen responses

o   PA systems must be congruent with culture and principles of the org

o   Primary purpose should be to help employees improve performance

o   All should be involved in modifying PA system

o   Focus of appraisal should be on behavior, because that is what is controllable

o   Workers must engage in job-relevant behavior and behaviors that promote cooperation and system improvement in order to be successful

o   Workers should be judged by absolute standards

o   Managers should be responsible for appraisals

## Fletcher & Perry, 2001

·         Discuss PA in different cultures

·         High power distance, 360 feedback is less likely with no appeals process

·         For high collectivism, feedback is likely to be subtle and focused on the group level, more positive and relationship focused for the purpose of development

·         Generally research on PA has shifted from pure measurement to including social and motivational aspects

## Viswesvaran et al., 2005 _JAP_

·         Use fancy stats to find a general factor of performance that accounts for a good deal of variability in correlated ratings (60.3%)

·         Halo does inflate correlations

o   33% for supervisor ratings

o   63% for peer ratings

## Borman & Motowidlo, 1993; 1997 _HP_

·         Define contextual performance and distinguish it from task performance

·         Contextual performance shapes social and psychological context in the workplace

o   E.g., OCBs

·         Supervisors weight task and contextual performance approximately equally when assessing performance

·         Contextual performance explains relationship between personality and performance

o   More strongly related to personality than overall performance

## Hoffman et al., 2012 _PP_

·         Develop frame of reference scales

·         Show scales are associated with increased variance due to dimensions, decreased dimension overlap, and decreased error

·         Helps to improve accuracy; similar to frame of reference training

## Borman, 1997

·         Review of 360 degree ratings

·         Generally findings show rating sources have relatively unique perspectives of performance

o   Reasons for disagreement are unclear

o   Need to know why org levels disagree and how to improve interpretation of 360 ratings

·         Need more research on whether sources provide incremental validity

o   Can predict subsequent performance from ratings in training or ratings of potential taken on the job

o   Can also correlate performance ratings concurrently with relevant external criteria

## Conway et al., 2001 _HP_

·         Meta looking at multisource ratings, incremental validity

·         Also looked at nomological net - relationships between sources and personality and ability

o   Peer, supervisor, subordinate, and objective measures

·         Subordinates and peers account for significant variance in objective measures avobe other sources; important to include in a rating system

·         Peers and subordinate ratings had smaller relationships with ability than supervisors

·         Rating relationships with personality variables were pretty low; supervisors had somewhat higher than was previously found

## Steele-Johnson et al., 2000

·         Review research on and develop comprehensive model for criteria

·         Argue each of the following affects dynamic criteria

o   Job variables – consistency, complexity, task interdependence

o   Task variables – consistency, complexity, task definition/structure

o   Org variables – technology changes, work process changes, situational strength and constraints

o   Learning-related variables – Skill acquisition and work experience

o   Also GMA…because GMA always predicts performance.

## Sturman et al., (2005) _JAP_

·         Meta on dynamic criteria and job complexity

·         Test-retest reliability of performance ranges from .83 (subjective, low complexity jobs) to .50 (objective measures, high complexity jobs)

·         Stability over 1 year ranges from .85 dto .67

·         As time increases, relationship between performance measurements decreases (simplex pattern/never reaches zero)

## Heilman & Chen (2005) _JAP_

·         Study that looks at gender and altruisim OCB

·         Women are punished for not being altruistic

·         Men receive benefits for being altruistic; not punished for not doing it

·         Women and men held to gender-stereotypic prescriptions

## Lievens et al., (2008) _JOOP_

·         Policies used by raters to weight task perf, OCB, CWB depends on the job, team culture, and source

·         Team-based culture = more weight given to OCB and less to task performance compared to less team oriented cultures

·         Peers = more weight to OCB and less to task perf compared to supervisors

## Whiting et al., 2008 _JAP_

·         Task performance, voice, and org loyalty all have significant effects on rater performance evaluations

·         Citizenship behaviors contribute substantially to ratings (helping, voice, loyalty)

## Heslin et al., (2005) _JAP_

·         Implicit theories of performance can influence raters

·         Raters who do not believe individuals can change are heavily influenced by first impressions and tend to rate less accurately when performance changes from this initial impression

·         Raters can be trained so they learn individuals can change; end up rating performance more accurately than without training

## Pulakos et al., (2012)

·         See “Adaptive Performance” section

## Heavey et al., (2013) _JAP_

·         Meta on turnover and performance outcomes

·         Human resource management investments and embeddedness signals were most strongly and consistently related to turnover

·         Also related to performance, such as customer satisfaction, production efficiency, sales efficiency, counterproductivity and error

## Borman & Smith (2012)

·         Review of objective measures

·         Basically see “Objective Measures” section

## McElroy et al., (2001) _JAP_

·         Looked at effect of turnover on performance

·         Divided turnover into voluntary, involuntary, and reduction-in-force

o   This distinction matters!!

·         Results found reduction-in-force was most detrimental for org performance

## Roth et al., 2005 _PP_

·         Meta of work sample validity

·         Mean r = .26 for work samples and job performance

o   Increased to .33 when corrected for attenuation

·         Validity is not as large as previously thought

·         Work samples related to GMA r = .32

## Lance et al., (2000)

·         Ratings for work samples are valid and unbiased

·         Raters must be trained

## Dalal (2005) Meta: CWB and OCB are Distinct and Moderately Correlated

·         Meta of relationship between OCB and CWB

·         CWB-OCB relationship -.32

·         CWB-OCB relationships at the facet level not strong; stronger relationships for facets within OCB/CWB (e.g., OCBI with OCBO)

·         CWB stronger relationships with antecedents than OCB

o   Job satisfaction, org commitment, justice, C, PA, NA

o   OCB-CWB relationship stronger when raters were supervisors compared to self-reports, when responses used behavioral frequencies compared to agreement, when antithetical items were included vs. not included

·         CWB and OCB are distinct

o   Eliminating high CWB does not mean you will get high OCB

Should be evaluated separately
